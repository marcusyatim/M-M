{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling\n",
    "\n",
    "### To perform topic modeling on the 'steps' column of the RAW_recipes.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    steps\n",
      "0       ['make a choice and proceed with recipe', 'dep...\n",
      "1       ['preheat oven to 425 degrees f', 'press dough...\n",
      "2       ['brown ground beef in large pot', 'add choppe...\n",
      "3       ['place potatoes in a large pot of lightly sal...\n",
      "4       ['mix all ingredients& boil for 2 1 / 2 hours ...\n",
      "...                                                   ...\n",
      "231632  ['heat oil in a 4-quart dutch oven', 'add cele...\n",
      "231633        ['mix all ingredients together thoroughly']\n",
      "231634  ['in a bowl , combine the mashed yolks and may...\n",
      "231635  ['place melted butter in a large mixing bowl a...\n",
      "231636  ['whip sugar and shortening in a large bowl , ...\n",
      "\n",
      "[231637 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle \n",
    "\n",
    "recipes = pd.read_csv('../../data/RAW_recipes.csv', usecols=['steps'])\n",
    "print (recipes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refer to ../data/topic-model/experiments.txt for experiment designs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "import nltk\n",
    "import string\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "'''\n",
    "- text = text.replace(\"'\",\"\") is used before the tokenisation to remove \"'\" because the tokenisation itself cannot separate\n",
    "  that properly and if not it appears at the front of every sentence.\n",
    "- Warning: Cell takes very long to process.\n",
    "'''\n",
    "# mystopwords = open('../../data/topic-model/stopwords/exp1.txt', 'r')\n",
    "# mystopwords = mystopwords.read().splitlines()\n",
    "mystopwords = stopwords.words(\"english\")\n",
    "WNlemma = nltk.WordNetLemmatizer()\n",
    "\n",
    "def pre_process(text):\n",
    "    text = text.replace(\"'\",\"\")\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [ t for t in tokens if t not in string.punctuation+\"’“”'\" ]\n",
    "    tokens = [ WNlemma.lemmatize(t.lower()) for t in tokens ]\n",
    "    tokens = [ t for t in tokens if t not in mystopwords ]\n",
    "    tokens = [ t for t in tokens if len(t) >= 3 ]\n",
    "    return(tokens)\n",
    "\n",
    "text = recipes['steps']\n",
    "\n",
    "# For testing on individual recipes (uncomment when required)\n",
    "# tokens = pre_process(text[1])\n",
    "# print (tokens)\n",
    "\n",
    "tokens = text.apply(pre_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save tokens\n",
    "tokens.to_pickle('../../data/topic-model/tokens/exp2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokens\n",
    "# tokens = pd.read_pickle('../../data/topic-model/tokens/exp1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-19 13:43:46,535 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2021-09-19 13:43:47,052 : INFO : adding document #10000 to Dictionary(10159 unique tokens: ['350', 'aluminum', 'bake', 'baking', 'burn']...)\n",
      "2021-09-19 13:43:47,571 : INFO : adding document #20000 to Dictionary(14308 unique tokens: ['350', 'aluminum', 'bake', 'baking', 'burn']...)\n",
      "2021-09-19 13:43:48,090 : INFO : adding document #30000 to Dictionary(17597 unique tokens: ['350', 'aluminum', 'bake', 'baking', 'burn']...)\n",
      "2021-09-19 13:43:48,617 : INFO : adding document #40000 to Dictionary(20509 unique tokens: ['350', 'aluminum', 'bake', 'baking', 'burn']...)\n",
      "2021-09-19 13:43:49,161 : INFO : adding document #50000 to Dictionary(22868 unique tokens: ['350', 'aluminum', 'bake', 'baking', 'burn']...)\n",
      "2021-09-19 13:43:49,704 : INFO : adding document #60000 to Dictionary(25287 unique tokens: ['350', 'aluminum', 'bake', 'baking', 'burn']...)\n",
      "2021-09-19 13:43:50,189 : INFO : adding document #70000 to Dictionary(27030 unique tokens: ['350', 'aluminum', 'bake', 'baking', 'burn']...)\n",
      "2021-09-19 13:43:50,688 : INFO : adding document #80000 to Dictionary(29058 unique tokens: ['350', 'aluminum', 'bake', 'baking', 'burn']...)\n",
      "2021-09-19 13:43:51,208 : INFO : adding document #90000 to Dictionary(31288 unique tokens: ['350', 'aluminum', 'bake', 'baking', 'burn']...)\n",
      "2021-09-19 13:43:51,729 : INFO : adding document #100000 to Dictionary(33151 unique tokens: ['350', 'aluminum', 'bake', 'baking', 'burn']...)\n",
      "2021-09-19 13:43:52,235 : INFO : adding document #110000 to Dictionary(35026 unique tokens: ['350', 'aluminum', 'bake', 'baking', 'burn']...)\n",
      "2021-09-19 13:43:52,767 : INFO : adding document #120000 to Dictionary(37100 unique tokens: ['350', 'aluminum', 'bake', 'baking', 'burn']...)\n",
      "2021-09-19 13:43:53,300 : INFO : adding document #130000 to Dictionary(38793 unique tokens: ['350', 'aluminum', 'bake', 'baking', 'burn']...)\n",
      "2021-09-19 13:43:53,865 : INFO : adding document #140000 to Dictionary(40464 unique tokens: ['350', 'aluminum', 'bake', 'baking', 'burn']...)\n",
      "2021-09-19 13:43:54,411 : INFO : adding document #150000 to Dictionary(42086 unique tokens: ['350', 'aluminum', 'bake', 'baking', 'burn']...)\n",
      "2021-09-19 13:43:54,980 : INFO : adding document #160000 to Dictionary(43610 unique tokens: ['350', 'aluminum', 'bake', 'baking', 'burn']...)\n",
      "2021-09-19 13:43:55,515 : INFO : adding document #170000 to Dictionary(45074 unique tokens: ['350', 'aluminum', 'bake', 'baking', 'burn']...)\n",
      "2021-09-19 13:43:56,067 : INFO : adding document #180000 to Dictionary(46719 unique tokens: ['350', 'aluminum', 'bake', 'baking', 'burn']...)\n",
      "2021-09-19 13:43:56,580 : INFO : adding document #190000 to Dictionary(48085 unique tokens: ['350', 'aluminum', 'bake', 'baking', 'burn']...)\n",
      "2021-09-19 13:43:57,119 : INFO : adding document #200000 to Dictionary(49396 unique tokens: ['350', 'aluminum', 'bake', 'baking', 'burn']...)\n",
      "2021-09-19 13:43:57,635 : INFO : adding document #210000 to Dictionary(50655 unique tokens: ['350', 'aluminum', 'bake', 'baking', 'burn']...)\n",
      "2021-09-19 13:43:58,220 : INFO : adding document #220000 to Dictionary(52243 unique tokens: ['350', 'aluminum', 'bake', 'baking', 'burn']...)\n",
      "2021-09-19 13:43:58,756 : INFO : adding document #230000 to Dictionary(53568 unique tokens: ['350', 'aluminum', 'bake', 'baking', 'burn']...)\n",
      "2021-09-19 13:43:58,840 : INFO : built Dictionary(53776 unique tokens: ['350', 'aluminum', 'bake', 'baking', 'burn']...) from 231637 documents (total 13505596 corpus positions)\n",
      "2021-09-19 13:43:58,840 : INFO : Dictionary lifecycle event {'msg': \"built Dictionary(53776 unique tokens: ['350', 'aluminum', 'bake', 'baking', 'burn']...) from 231637 documents (total 13505596 corpus positions)\", 'datetime': '2021-09-19T13:43:58.840544', 'gensim': '4.0.1', 'python': '3.9.6 | packaged by conda-forge | (default, Jul  6 2021, 08:46:02) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.18363-SP0', 'event': 'created'}\n",
      "2021-09-19 13:43:58,902 : INFO : discarding 50704 tokens: [('comfortable', 46), ('opt', 46), ('piloncillo', 9), ('350^f', 18), ('alouette', 18), ('amish', 11), ('asealed', 1), ('life', 90), ('mother-in-law', 5), ('toseal', 1)]...\n",
      "2021-09-19 13:43:58,902 : INFO : keeping 3072 tokens which were in no less than 100 and no more than 162145 (=70.0%) documents\n",
      "2021-09-19 13:43:58,924 : INFO : resulting dictionary: Dictionary(3072 unique tokens: ['350', 'aluminum', 'bake', 'baking', 'burn']...)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(53776 unique tokens: ['350', 'aluminum', 'bake', 'baking', 'burn']...)\n",
      "Dictionary(3072 unique tokens: ['350', 'aluminum', 'bake', 'baking', 'burn']...)\n"
     ]
    }
   ],
   "source": [
    "# Use dictionary (built from corpus) to prepare a DTM (using frequency)\n",
    "import logging\n",
    "import gensim \n",
    "from gensim import corpora\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "dictionary = corpora.Dictionary(tokens)\n",
    "print(dictionary)\n",
    "\n",
    "# Filter off any words with document frequency less than #, or appearing in more than #% documents.\n",
    "dictionary.filter_extremes(no_below=100, no_above=0.7)\n",
    "\"\"\"\n",
    "        no_below : int, optional\n",
    "            Keep tokens which are contained in at least `no_below` documents.\n",
    "        no_above : float, optional\n",
    "            Keep tokens which are contained in no more than `no_above` documents\n",
    "            (fraction of total corpus size, not an absolute number).\n",
    "\"\"\"\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-19 13:44:45,894 : INFO : Dictionary lifecycle event {'fname_or_handle': '../Data/topic-model/dicts/exp2.dict', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2021-09-19T13:44:45.894430', 'gensim': '4.0.1', 'python': '3.9.6 | packaged by conda-forge | (default, Jul  6 2021, 08:46:02) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.18363-SP0', 'event': 'saving'}\n",
      "2021-09-19 13:44:45,900 : INFO : saved ../Data/topic-model/dicts/exp2.dict\n"
     ]
    }
   ],
   "source": [
    "# Save dictionary\n",
    "dictionary.save('../../data/topic-model/dicts/exp2.dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-19 14:22:47,290 : INFO : loading Dictionary object from ../Data/topic-model/dicts/exp1.dict\n",
      "2021-09-19 14:22:47,701 : INFO : Dictionary lifecycle event {'fname': '../Data/topic-model/dicts/exp1.dict', 'datetime': '2021-09-19T14:22:47.701248', 'gensim': '4.0.1', 'python': '3.9.6 | packaged by conda-forge | (default, Jul  6 2021, 08:46:02) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.18363-SP0', 'event': 'loaded'}\n"
     ]
    }
   ],
   "source": [
    "# Load dictionary\n",
    "# dictionary = corpora.Dictionary.load('../../data/topic-model/dicts/exp1.dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtm here is a list of lists, which is exactly a matrix\n",
    "'''\n",
    " Warning: Cell takes very VERY long to process.\n",
    "'''\n",
    "dtm = [dictionary.doc2bow(d) for d in tokens]\n",
    "lda = gensim.models.ldamodel.LdaModel(dtm, num_topics=15, id2word=dictionary, passes=10, chunksize=128, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-19 14:04:27,589 : INFO : LdaState lifecycle event {'fname_or_handle': '../Data/topic-model/models/exp2.model.state', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2021-09-19T14:04:27.589154', 'gensim': '4.0.1', 'python': '3.9.6 | packaged by conda-forge | (default, Jul  6 2021, 08:46:02) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.18363-SP0', 'event': 'saving'}\n",
      "2021-09-19 14:04:28,912 : INFO : saved ../Data/topic-model/models/exp2.model.state\n",
      "2021-09-19 14:04:28,924 : INFO : LdaModel lifecycle event {'fname_or_handle': '../Data/topic-model/models/exp2.model', 'separately': \"['expElogbeta', 'sstats']\", 'sep_limit': 10485760, 'ignore': ['state', 'dispatcher', 'id2word'], 'datetime': '2021-09-19T14:04:28.924394', 'gensim': '4.0.1', 'python': '3.9.6 | packaged by conda-forge | (default, Jul  6 2021, 08:46:02) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.18363-SP0', 'event': 'saving'}\n",
      "2021-09-19 14:04:28,925 : INFO : storing np array 'expElogbeta' to ../Data/topic-model/models/exp2.model.expElogbeta.npy\n",
      "2021-09-19 14:04:28,930 : INFO : not storing attribute state\n",
      "2021-09-19 14:04:28,931 : INFO : not storing attribute dispatcher\n",
      "2021-09-19 14:04:28,932 : INFO : not storing attribute id2word\n",
      "2021-09-19 14:04:28,936 : INFO : saved ../Data/topic-model/models/exp2.model\n"
     ]
    }
   ],
   "source": [
    "# Save LDA model\n",
    "lda.save('../../data/topic-model/models/exp2.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-19 14:23:11,454 : INFO : loading LdaModel object from ../Data/topic-model/models/exp1.model\n",
      "2021-09-19 14:23:11,456 : INFO : loading expElogbeta from ../Data/topic-model/models/exp1.model.expElogbeta.npy with mmap=None\n",
      "2021-09-19 14:23:11,459 : INFO : setting ignored attribute state to None\n",
      "2021-09-19 14:23:11,459 : INFO : setting ignored attribute dispatcher to None\n",
      "2021-09-19 14:23:11,460 : INFO : setting ignored attribute id2word to None\n",
      "2021-09-19 14:23:11,460 : INFO : LdaModel lifecycle event {'fname': '../Data/topic-model/models/exp1.model', 'datetime': '2021-09-19T14:23:11.460833', 'gensim': '4.0.1', 'python': '3.9.6 | packaged by conda-forge | (default, Jul  6 2021, 08:46:02) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.18363-SP0', 'event': 'loaded'}\n",
      "2021-09-19 14:23:11,462 : INFO : loading LdaState object from ../Data/topic-model/models/exp1.model.state\n",
      "2021-09-19 14:23:11,464 : INFO : LdaState lifecycle event {'fname': '../Data/topic-model/models/exp1.model.state', 'datetime': '2021-09-19T14:23:11.464823', 'gensim': '4.0.1', 'python': '3.9.6 | packaged by conda-forge | (default, Jul  6 2021, 08:46:02) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.18363-SP0', 'event': 'loaded'}\n"
     ]
    }
   ],
   "source": [
    "# Load LDA model\n",
    "# lda = gensim.models.ldamodel.LdaModel.load('../../data/topic-model/models/exp1.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dtm\n",
    "with open('../../data/topic-model/dtms/exp1.pkl', 'wb') as f:\n",
    "    pickle.dump(dtm, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dtm\n",
    "# with open('../../data/topic-model/dtms/exp2.pkl', 'rb') as f:\n",
    "#     dtm = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marcu\\anaconda3\\envs\\nlp\\lib\\site-packages\\pyLDAvis\\_prepare.py:246: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  default_term_info = default_term_info.sort_values(\n"
     ]
    }
   ],
   "source": [
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import pyLDAvis\n",
    "\n",
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "LDAvis_prepared = gensimvis.prepare(lda, dtm, dictionary)\n",
    "pyLDAvis.save_html(LDAvis_prepared, '../../data/topic-model/pyLDAvis/exp2.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-19 14:23:29,244 : INFO : CorpusAccumulator accumulated stats from 1000 documents\n",
      "2021-09-19 14:23:29,268 : INFO : CorpusAccumulator accumulated stats from 2000 documents\n",
      "2021-09-19 14:23:29,292 : INFO : CorpusAccumulator accumulated stats from 3000 documents\n",
      "2021-09-19 14:23:29,317 : INFO : CorpusAccumulator accumulated stats from 4000 documents\n",
      "2021-09-19 14:23:29,341 : INFO : CorpusAccumulator accumulated stats from 5000 documents\n",
      "2021-09-19 14:23:29,365 : INFO : CorpusAccumulator accumulated stats from 6000 documents\n",
      "2021-09-19 14:23:29,388 : INFO : CorpusAccumulator accumulated stats from 7000 documents\n",
      "2021-09-19 14:23:29,413 : INFO : CorpusAccumulator accumulated stats from 8000 documents\n",
      "2021-09-19 14:23:29,438 : INFO : CorpusAccumulator accumulated stats from 9000 documents\n",
      "2021-09-19 14:23:29,460 : INFO : CorpusAccumulator accumulated stats from 10000 documents\n",
      "2021-09-19 14:23:29,485 : INFO : CorpusAccumulator accumulated stats from 11000 documents\n",
      "2021-09-19 14:23:29,508 : INFO : CorpusAccumulator accumulated stats from 12000 documents\n",
      "2021-09-19 14:23:29,532 : INFO : CorpusAccumulator accumulated stats from 13000 documents\n",
      "2021-09-19 14:23:29,556 : INFO : CorpusAccumulator accumulated stats from 14000 documents\n",
      "2021-09-19 14:23:29,581 : INFO : CorpusAccumulator accumulated stats from 15000 documents\n",
      "2021-09-19 14:23:29,607 : INFO : CorpusAccumulator accumulated stats from 16000 documents\n",
      "2021-09-19 14:23:29,633 : INFO : CorpusAccumulator accumulated stats from 17000 documents\n",
      "2021-09-19 14:23:29,656 : INFO : CorpusAccumulator accumulated stats from 18000 documents\n",
      "2021-09-19 14:23:29,682 : INFO : CorpusAccumulator accumulated stats from 19000 documents\n",
      "2021-09-19 14:23:29,705 : INFO : CorpusAccumulator accumulated stats from 20000 documents\n",
      "2021-09-19 14:23:29,737 : INFO : CorpusAccumulator accumulated stats from 21000 documents\n",
      "2021-09-19 14:23:29,760 : INFO : CorpusAccumulator accumulated stats from 22000 documents\n",
      "2021-09-19 14:23:29,785 : INFO : CorpusAccumulator accumulated stats from 23000 documents\n",
      "2021-09-19 14:23:29,810 : INFO : CorpusAccumulator accumulated stats from 24000 documents\n",
      "2021-09-19 14:23:29,839 : INFO : CorpusAccumulator accumulated stats from 25000 documents\n",
      "2021-09-19 14:23:29,863 : INFO : CorpusAccumulator accumulated stats from 26000 documents\n",
      "2021-09-19 14:23:29,888 : INFO : CorpusAccumulator accumulated stats from 27000 documents\n",
      "2021-09-19 14:23:29,914 : INFO : CorpusAccumulator accumulated stats from 28000 documents\n",
      "2021-09-19 14:23:29,939 : INFO : CorpusAccumulator accumulated stats from 29000 documents\n",
      "2021-09-19 14:23:29,960 : INFO : CorpusAccumulator accumulated stats from 30000 documents\n",
      "2021-09-19 14:23:29,985 : INFO : CorpusAccumulator accumulated stats from 31000 documents\n",
      "2021-09-19 14:23:30,009 : INFO : CorpusAccumulator accumulated stats from 32000 documents\n",
      "2021-09-19 14:23:30,036 : INFO : CorpusAccumulator accumulated stats from 33000 documents\n",
      "2021-09-19 14:23:30,058 : INFO : CorpusAccumulator accumulated stats from 34000 documents\n",
      "2021-09-19 14:23:30,081 : INFO : CorpusAccumulator accumulated stats from 35000 documents\n",
      "2021-09-19 14:23:30,107 : INFO : CorpusAccumulator accumulated stats from 36000 documents\n",
      "2021-09-19 14:23:30,131 : INFO : CorpusAccumulator accumulated stats from 37000 documents\n",
      "2021-09-19 14:23:30,155 : INFO : CorpusAccumulator accumulated stats from 38000 documents\n",
      "2021-09-19 14:23:30,179 : INFO : CorpusAccumulator accumulated stats from 39000 documents\n",
      "2021-09-19 14:23:30,202 : INFO : CorpusAccumulator accumulated stats from 40000 documents\n",
      "2021-09-19 14:23:30,225 : INFO : CorpusAccumulator accumulated stats from 41000 documents\n",
      "2021-09-19 14:23:30,249 : INFO : CorpusAccumulator accumulated stats from 42000 documents\n",
      "2021-09-19 14:23:30,276 : INFO : CorpusAccumulator accumulated stats from 43000 documents\n",
      "2021-09-19 14:23:30,303 : INFO : CorpusAccumulator accumulated stats from 44000 documents\n",
      "2021-09-19 14:23:30,334 : INFO : CorpusAccumulator accumulated stats from 45000 documents\n",
      "2021-09-19 14:23:30,365 : INFO : CorpusAccumulator accumulated stats from 46000 documents\n",
      "2021-09-19 14:23:30,395 : INFO : CorpusAccumulator accumulated stats from 47000 documents\n",
      "2021-09-19 14:23:30,420 : INFO : CorpusAccumulator accumulated stats from 48000 documents\n",
      "2021-09-19 14:23:30,447 : INFO : CorpusAccumulator accumulated stats from 49000 documents\n",
      "2021-09-19 14:23:30,475 : INFO : CorpusAccumulator accumulated stats from 50000 documents\n",
      "2021-09-19 14:23:30,505 : INFO : CorpusAccumulator accumulated stats from 51000 documents\n",
      "2021-09-19 14:23:30,534 : INFO : CorpusAccumulator accumulated stats from 52000 documents\n",
      "2021-09-19 14:23:30,561 : INFO : CorpusAccumulator accumulated stats from 53000 documents\n",
      "2021-09-19 14:23:30,584 : INFO : CorpusAccumulator accumulated stats from 54000 documents\n",
      "2021-09-19 14:23:30,612 : INFO : CorpusAccumulator accumulated stats from 55000 documents\n",
      "2021-09-19 14:23:30,635 : INFO : CorpusAccumulator accumulated stats from 56000 documents\n",
      "2021-09-19 14:23:30,661 : INFO : CorpusAccumulator accumulated stats from 57000 documents\n",
      "2021-09-19 14:23:30,687 : INFO : CorpusAccumulator accumulated stats from 58000 documents\n",
      "2021-09-19 14:23:30,712 : INFO : CorpusAccumulator accumulated stats from 59000 documents\n",
      "2021-09-19 14:23:30,736 : INFO : CorpusAccumulator accumulated stats from 60000 documents\n",
      "2021-09-19 14:23:30,760 : INFO : CorpusAccumulator accumulated stats from 61000 documents\n",
      "2021-09-19 14:23:30,786 : INFO : CorpusAccumulator accumulated stats from 62000 documents\n",
      "2021-09-19 14:23:30,809 : INFO : CorpusAccumulator accumulated stats from 63000 documents\n",
      "2021-09-19 14:23:30,836 : INFO : CorpusAccumulator accumulated stats from 64000 documents\n",
      "2021-09-19 14:23:30,862 : INFO : CorpusAccumulator accumulated stats from 65000 documents\n",
      "2021-09-19 14:23:30,883 : INFO : CorpusAccumulator accumulated stats from 66000 documents\n",
      "2021-09-19 14:23:30,903 : INFO : CorpusAccumulator accumulated stats from 67000 documents\n",
      "2021-09-19 14:23:30,929 : INFO : CorpusAccumulator accumulated stats from 68000 documents\n",
      "2021-09-19 14:23:30,953 : INFO : CorpusAccumulator accumulated stats from 69000 documents\n",
      "2021-09-19 14:23:30,979 : INFO : CorpusAccumulator accumulated stats from 70000 documents\n",
      "2021-09-19 14:23:31,004 : INFO : CorpusAccumulator accumulated stats from 71000 documents\n",
      "2021-09-19 14:23:31,028 : INFO : CorpusAccumulator accumulated stats from 72000 documents\n",
      "2021-09-19 14:23:31,053 : INFO : CorpusAccumulator accumulated stats from 73000 documents\n",
      "2021-09-19 14:23:31,078 : INFO : CorpusAccumulator accumulated stats from 74000 documents\n",
      "2021-09-19 14:23:31,100 : INFO : CorpusAccumulator accumulated stats from 75000 documents\n",
      "2021-09-19 14:23:31,123 : INFO : CorpusAccumulator accumulated stats from 76000 documents\n",
      "2021-09-19 14:23:31,145 : INFO : CorpusAccumulator accumulated stats from 77000 documents\n",
      "2021-09-19 14:23:31,166 : INFO : CorpusAccumulator accumulated stats from 78000 documents\n",
      "2021-09-19 14:23:31,190 : INFO : CorpusAccumulator accumulated stats from 79000 documents\n",
      "2021-09-19 14:23:31,216 : INFO : CorpusAccumulator accumulated stats from 80000 documents\n",
      "2021-09-19 14:23:31,243 : INFO : CorpusAccumulator accumulated stats from 81000 documents\n",
      "2021-09-19 14:23:31,266 : INFO : CorpusAccumulator accumulated stats from 82000 documents\n",
      "2021-09-19 14:23:31,290 : INFO : CorpusAccumulator accumulated stats from 83000 documents\n",
      "2021-09-19 14:23:31,315 : INFO : CorpusAccumulator accumulated stats from 84000 documents\n",
      "2021-09-19 14:23:31,340 : INFO : CorpusAccumulator accumulated stats from 85000 documents\n",
      "2021-09-19 14:23:31,365 : INFO : CorpusAccumulator accumulated stats from 86000 documents\n",
      "2021-09-19 14:23:31,391 : INFO : CorpusAccumulator accumulated stats from 87000 documents\n",
      "2021-09-19 14:23:31,416 : INFO : CorpusAccumulator accumulated stats from 88000 documents\n",
      "2021-09-19 14:23:31,439 : INFO : CorpusAccumulator accumulated stats from 89000 documents\n",
      "2021-09-19 14:23:31,463 : INFO : CorpusAccumulator accumulated stats from 90000 documents\n",
      "2021-09-19 14:23:31,485 : INFO : CorpusAccumulator accumulated stats from 91000 documents\n",
      "2021-09-19 14:23:31,510 : INFO : CorpusAccumulator accumulated stats from 92000 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-19 14:23:31,535 : INFO : CorpusAccumulator accumulated stats from 93000 documents\n",
      "2021-09-19 14:23:31,559 : INFO : CorpusAccumulator accumulated stats from 94000 documents\n",
      "2021-09-19 14:23:31,585 : INFO : CorpusAccumulator accumulated stats from 95000 documents\n",
      "2021-09-19 14:23:31,607 : INFO : CorpusAccumulator accumulated stats from 96000 documents\n",
      "2021-09-19 14:23:31,631 : INFO : CorpusAccumulator accumulated stats from 97000 documents\n",
      "2021-09-19 14:23:31,652 : INFO : CorpusAccumulator accumulated stats from 98000 documents\n",
      "2021-09-19 14:23:31,675 : INFO : CorpusAccumulator accumulated stats from 99000 documents\n",
      "2021-09-19 14:23:31,700 : INFO : CorpusAccumulator accumulated stats from 100000 documents\n",
      "2021-09-19 14:23:31,726 : INFO : CorpusAccumulator accumulated stats from 101000 documents\n",
      "2021-09-19 14:23:31,749 : INFO : CorpusAccumulator accumulated stats from 102000 documents\n",
      "2021-09-19 14:23:31,772 : INFO : CorpusAccumulator accumulated stats from 103000 documents\n",
      "2021-09-19 14:23:31,795 : INFO : CorpusAccumulator accumulated stats from 104000 documents\n",
      "2021-09-19 14:23:31,821 : INFO : CorpusAccumulator accumulated stats from 105000 documents\n",
      "2021-09-19 14:23:31,847 : INFO : CorpusAccumulator accumulated stats from 106000 documents\n",
      "2021-09-19 14:23:31,874 : INFO : CorpusAccumulator accumulated stats from 107000 documents\n",
      "2021-09-19 14:23:31,896 : INFO : CorpusAccumulator accumulated stats from 108000 documents\n",
      "2021-09-19 14:23:31,920 : INFO : CorpusAccumulator accumulated stats from 109000 documents\n",
      "2021-09-19 14:23:31,946 : INFO : CorpusAccumulator accumulated stats from 110000 documents\n",
      "2021-09-19 14:23:31,977 : INFO : CorpusAccumulator accumulated stats from 111000 documents\n",
      "2021-09-19 14:23:32,008 : INFO : CorpusAccumulator accumulated stats from 112000 documents\n",
      "2021-09-19 14:23:32,033 : INFO : CorpusAccumulator accumulated stats from 113000 documents\n",
      "2021-09-19 14:23:32,058 : INFO : CorpusAccumulator accumulated stats from 114000 documents\n",
      "2021-09-19 14:23:32,084 : INFO : CorpusAccumulator accumulated stats from 115000 documents\n",
      "2021-09-19 14:23:32,109 : INFO : CorpusAccumulator accumulated stats from 116000 documents\n",
      "2021-09-19 14:23:32,134 : INFO : CorpusAccumulator accumulated stats from 117000 documents\n",
      "2021-09-19 14:23:32,158 : INFO : CorpusAccumulator accumulated stats from 118000 documents\n",
      "2021-09-19 14:23:32,185 : INFO : CorpusAccumulator accumulated stats from 119000 documents\n",
      "2021-09-19 14:23:32,213 : INFO : CorpusAccumulator accumulated stats from 120000 documents\n",
      "2021-09-19 14:23:32,239 : INFO : CorpusAccumulator accumulated stats from 121000 documents\n",
      "2021-09-19 14:23:32,267 : INFO : CorpusAccumulator accumulated stats from 122000 documents\n",
      "2021-09-19 14:23:32,294 : INFO : CorpusAccumulator accumulated stats from 123000 documents\n",
      "2021-09-19 14:23:32,319 : INFO : CorpusAccumulator accumulated stats from 124000 documents\n",
      "2021-09-19 14:23:32,343 : INFO : CorpusAccumulator accumulated stats from 125000 documents\n",
      "2021-09-19 14:23:32,367 : INFO : CorpusAccumulator accumulated stats from 126000 documents\n",
      "2021-09-19 14:23:32,389 : INFO : CorpusAccumulator accumulated stats from 127000 documents\n",
      "2021-09-19 14:23:32,413 : INFO : CorpusAccumulator accumulated stats from 128000 documents\n",
      "2021-09-19 14:23:32,440 : INFO : CorpusAccumulator accumulated stats from 129000 documents\n",
      "2021-09-19 14:23:32,462 : INFO : CorpusAccumulator accumulated stats from 130000 documents\n",
      "2021-09-19 14:23:32,485 : INFO : CorpusAccumulator accumulated stats from 131000 documents\n",
      "2021-09-19 14:23:32,510 : INFO : CorpusAccumulator accumulated stats from 132000 documents\n",
      "2021-09-19 14:23:32,535 : INFO : CorpusAccumulator accumulated stats from 133000 documents\n",
      "2021-09-19 14:23:32,561 : INFO : CorpusAccumulator accumulated stats from 134000 documents\n",
      "2021-09-19 14:23:32,585 : INFO : CorpusAccumulator accumulated stats from 135000 documents\n",
      "2021-09-19 14:23:32,607 : INFO : CorpusAccumulator accumulated stats from 136000 documents\n",
      "2021-09-19 14:23:32,632 : INFO : CorpusAccumulator accumulated stats from 137000 documents\n",
      "2021-09-19 14:23:32,654 : INFO : CorpusAccumulator accumulated stats from 138000 documents\n",
      "2021-09-19 14:23:32,677 : INFO : CorpusAccumulator accumulated stats from 139000 documents\n",
      "2021-09-19 14:23:32,701 : INFO : CorpusAccumulator accumulated stats from 140000 documents\n",
      "2021-09-19 14:23:32,727 : INFO : CorpusAccumulator accumulated stats from 141000 documents\n",
      "2021-09-19 14:23:32,749 : INFO : CorpusAccumulator accumulated stats from 142000 documents\n",
      "2021-09-19 14:23:32,772 : INFO : CorpusAccumulator accumulated stats from 143000 documents\n",
      "2021-09-19 14:23:32,798 : INFO : CorpusAccumulator accumulated stats from 144000 documents\n",
      "2021-09-19 14:23:32,821 : INFO : CorpusAccumulator accumulated stats from 145000 documents\n",
      "2021-09-19 14:23:32,844 : INFO : CorpusAccumulator accumulated stats from 146000 documents\n",
      "2021-09-19 14:23:32,869 : INFO : CorpusAccumulator accumulated stats from 147000 documents\n",
      "2021-09-19 14:23:32,894 : INFO : CorpusAccumulator accumulated stats from 148000 documents\n",
      "2021-09-19 14:23:32,923 : INFO : CorpusAccumulator accumulated stats from 149000 documents\n",
      "2021-09-19 14:23:32,947 : INFO : CorpusAccumulator accumulated stats from 150000 documents\n",
      "2021-09-19 14:23:32,973 : INFO : CorpusAccumulator accumulated stats from 151000 documents\n",
      "2021-09-19 14:23:33,002 : INFO : CorpusAccumulator accumulated stats from 152000 documents\n",
      "2021-09-19 14:23:33,029 : INFO : CorpusAccumulator accumulated stats from 153000 documents\n",
      "2021-09-19 14:23:33,055 : INFO : CorpusAccumulator accumulated stats from 154000 documents\n",
      "2021-09-19 14:23:33,082 : INFO : CorpusAccumulator accumulated stats from 155000 documents\n",
      "2021-09-19 14:23:33,104 : INFO : CorpusAccumulator accumulated stats from 156000 documents\n",
      "2021-09-19 14:23:33,130 : INFO : CorpusAccumulator accumulated stats from 157000 documents\n",
      "2021-09-19 14:23:33,155 : INFO : CorpusAccumulator accumulated stats from 158000 documents\n",
      "2021-09-19 14:23:33,181 : INFO : CorpusAccumulator accumulated stats from 159000 documents\n",
      "2021-09-19 14:23:33,209 : INFO : CorpusAccumulator accumulated stats from 160000 documents\n",
      "2021-09-19 14:23:33,234 : INFO : CorpusAccumulator accumulated stats from 161000 documents\n",
      "2021-09-19 14:23:33,264 : INFO : CorpusAccumulator accumulated stats from 162000 documents\n",
      "2021-09-19 14:23:33,290 : INFO : CorpusAccumulator accumulated stats from 163000 documents\n",
      "2021-09-19 14:23:33,319 : INFO : CorpusAccumulator accumulated stats from 164000 documents\n",
      "2021-09-19 14:23:33,346 : INFO : CorpusAccumulator accumulated stats from 165000 documents\n",
      "2021-09-19 14:23:33,371 : INFO : CorpusAccumulator accumulated stats from 166000 documents\n",
      "2021-09-19 14:23:33,398 : INFO : CorpusAccumulator accumulated stats from 167000 documents\n",
      "2021-09-19 14:23:33,424 : INFO : CorpusAccumulator accumulated stats from 168000 documents\n",
      "2021-09-19 14:23:33,446 : INFO : CorpusAccumulator accumulated stats from 169000 documents\n",
      "2021-09-19 14:23:33,468 : INFO : CorpusAccumulator accumulated stats from 170000 documents\n",
      "2021-09-19 14:23:33,491 : INFO : CorpusAccumulator accumulated stats from 171000 documents\n",
      "2021-09-19 14:23:33,515 : INFO : CorpusAccumulator accumulated stats from 172000 documents\n",
      "2021-09-19 14:23:33,537 : INFO : CorpusAccumulator accumulated stats from 173000 documents\n",
      "2021-09-19 14:23:33,560 : INFO : CorpusAccumulator accumulated stats from 174000 documents\n",
      "2021-09-19 14:23:33,587 : INFO : CorpusAccumulator accumulated stats from 175000 documents\n",
      "2021-09-19 14:23:33,614 : INFO : CorpusAccumulator accumulated stats from 176000 documents\n",
      "2021-09-19 14:23:33,638 : INFO : CorpusAccumulator accumulated stats from 177000 documents\n",
      "2021-09-19 14:23:33,662 : INFO : CorpusAccumulator accumulated stats from 178000 documents\n",
      "2021-09-19 14:23:33,687 : INFO : CorpusAccumulator accumulated stats from 179000 documents\n",
      "2021-09-19 14:23:33,709 : INFO : CorpusAccumulator accumulated stats from 180000 documents\n",
      "2021-09-19 14:23:33,733 : INFO : CorpusAccumulator accumulated stats from 181000 documents\n",
      "2021-09-19 14:23:33,757 : INFO : CorpusAccumulator accumulated stats from 182000 documents\n",
      "2021-09-19 14:23:33,784 : INFO : CorpusAccumulator accumulated stats from 183000 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-19 14:23:33,812 : INFO : CorpusAccumulator accumulated stats from 184000 documents\n",
      "2021-09-19 14:23:33,837 : INFO : CorpusAccumulator accumulated stats from 185000 documents\n",
      "2021-09-19 14:23:33,864 : INFO : CorpusAccumulator accumulated stats from 186000 documents\n",
      "2021-09-19 14:23:33,890 : INFO : CorpusAccumulator accumulated stats from 187000 documents\n",
      "2021-09-19 14:23:33,912 : INFO : CorpusAccumulator accumulated stats from 188000 documents\n",
      "2021-09-19 14:23:33,935 : INFO : CorpusAccumulator accumulated stats from 189000 documents\n",
      "2021-09-19 14:23:33,959 : INFO : CorpusAccumulator accumulated stats from 190000 documents\n",
      "2021-09-19 14:23:33,983 : INFO : CorpusAccumulator accumulated stats from 191000 documents\n",
      "2021-09-19 14:23:34,009 : INFO : CorpusAccumulator accumulated stats from 192000 documents\n",
      "2021-09-19 14:23:34,034 : INFO : CorpusAccumulator accumulated stats from 193000 documents\n",
      "2021-09-19 14:23:34,059 : INFO : CorpusAccumulator accumulated stats from 194000 documents\n",
      "2021-09-19 14:23:34,083 : INFO : CorpusAccumulator accumulated stats from 195000 documents\n",
      "2021-09-19 14:23:34,113 : INFO : CorpusAccumulator accumulated stats from 196000 documents\n",
      "2021-09-19 14:23:34,137 : INFO : CorpusAccumulator accumulated stats from 197000 documents\n",
      "2021-09-19 14:23:34,162 : INFO : CorpusAccumulator accumulated stats from 198000 documents\n",
      "2021-09-19 14:23:34,186 : INFO : CorpusAccumulator accumulated stats from 199000 documents\n",
      "2021-09-19 14:23:34,212 : INFO : CorpusAccumulator accumulated stats from 200000 documents\n",
      "2021-09-19 14:23:34,235 : INFO : CorpusAccumulator accumulated stats from 201000 documents\n",
      "2021-09-19 14:23:34,265 : INFO : CorpusAccumulator accumulated stats from 202000 documents\n",
      "2021-09-19 14:23:34,289 : INFO : CorpusAccumulator accumulated stats from 203000 documents\n",
      "2021-09-19 14:23:34,312 : INFO : CorpusAccumulator accumulated stats from 204000 documents\n",
      "2021-09-19 14:23:34,334 : INFO : CorpusAccumulator accumulated stats from 205000 documents\n",
      "2021-09-19 14:23:34,357 : INFO : CorpusAccumulator accumulated stats from 206000 documents\n",
      "2021-09-19 14:23:34,384 : INFO : CorpusAccumulator accumulated stats from 207000 documents\n",
      "2021-09-19 14:23:34,411 : INFO : CorpusAccumulator accumulated stats from 208000 documents\n",
      "2021-09-19 14:23:34,434 : INFO : CorpusAccumulator accumulated stats from 209000 documents\n",
      "2021-09-19 14:23:34,457 : INFO : CorpusAccumulator accumulated stats from 210000 documents\n",
      "2021-09-19 14:23:34,481 : INFO : CorpusAccumulator accumulated stats from 211000 documents\n",
      "2021-09-19 14:23:34,505 : INFO : CorpusAccumulator accumulated stats from 212000 documents\n",
      "2021-09-19 14:23:34,531 : INFO : CorpusAccumulator accumulated stats from 213000 documents\n",
      "2021-09-19 14:23:34,555 : INFO : CorpusAccumulator accumulated stats from 214000 documents\n",
      "2021-09-19 14:23:34,578 : INFO : CorpusAccumulator accumulated stats from 215000 documents\n",
      "2021-09-19 14:23:34,600 : INFO : CorpusAccumulator accumulated stats from 216000 documents\n",
      "2021-09-19 14:23:34,628 : INFO : CorpusAccumulator accumulated stats from 217000 documents\n",
      "2021-09-19 14:23:34,651 : INFO : CorpusAccumulator accumulated stats from 218000 documents\n",
      "2021-09-19 14:23:34,676 : INFO : CorpusAccumulator accumulated stats from 219000 documents\n",
      "2021-09-19 14:23:34,704 : INFO : CorpusAccumulator accumulated stats from 220000 documents\n",
      "2021-09-19 14:23:34,732 : INFO : CorpusAccumulator accumulated stats from 221000 documents\n",
      "2021-09-19 14:23:34,757 : INFO : CorpusAccumulator accumulated stats from 222000 documents\n",
      "2021-09-19 14:23:34,785 : INFO : CorpusAccumulator accumulated stats from 223000 documents\n",
      "2021-09-19 14:23:34,809 : INFO : CorpusAccumulator accumulated stats from 224000 documents\n",
      "2021-09-19 14:23:34,832 : INFO : CorpusAccumulator accumulated stats from 225000 documents\n",
      "2021-09-19 14:23:34,856 : INFO : CorpusAccumulator accumulated stats from 226000 documents\n",
      "2021-09-19 14:23:34,883 : INFO : CorpusAccumulator accumulated stats from 227000 documents\n",
      "2021-09-19 14:23:34,910 : INFO : CorpusAccumulator accumulated stats from 228000 documents\n",
      "2021-09-19 14:23:34,942 : INFO : CorpusAccumulator accumulated stats from 229000 documents\n",
      "2021-09-19 14:23:34,966 : INFO : CorpusAccumulator accumulated stats from 230000 documents\n",
      "2021-09-19 14:23:34,989 : INFO : CorpusAccumulator accumulated stats from 231000 documents\n",
      "2021-09-19 14:23:39,211 : INFO : using ParallelWordOccurrenceAccumulator(processes=11, batch_size=64) to estimate probabilities from sliding windows\n",
      "2021-09-19 14:25:01,174 : INFO : 1713 batches submitted to accumulate stats from 109632 documents (-5679668 virtual)\n",
      "2021-09-19 14:25:49,468 : INFO : 2817 batches submitted to accumulate stats from 180288 documents (-9263465 virtual)\n",
      "2021-09-19 14:26:15,610 : INFO : 3428 batches submitted to accumulate stats from 219392 documents (-11268116 virtual)\n",
      "2021-09-19 14:26:15,881 : INFO : 3436 batches submitted to accumulate stats from 219904 documents (-11282423 virtual)\n",
      "2021-09-19 14:26:25,890 : INFO : 11 accumulators retrieved from output queue\n",
      "2021-09-19 14:26:26,084 : INFO : accumulated word occurrence stats for 1014405 virtual documents\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the coherence score of LDA models using the metrics for LDA\n",
    "'''\n",
    "u_mass:prefer the model close to 0. \n",
    "c_v: [0,1], prefer bigger value.   \n",
    "Do not fully rely on the coherence score.\n",
    "'''\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "cm_umass = CoherenceModel(lda, dictionary=dictionary, corpus=dtm, coherence='u_mass')\n",
    "cm_cv = CoherenceModel(lda, dictionary=dictionary, texts=tokens, coherence='c_v')\n",
    "lda_umass = cm_umass.get_coherence()\n",
    "lda_cv = cm_cv.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.2833287487837315\n",
      "0.43888768907805975\n"
     ]
    }
   ],
   "source": [
    "print(lda_umass)\n",
    "print(lda_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

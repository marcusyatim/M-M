{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e6978ee",
   "metadata": {},
   "source": [
    "# Topic Top N\n",
    "### Once we have our topics, we want to look at the Top N words for each topic. We also want to expand these words by including their synonyms, hyponyms, hypernyms, meronyms, holonyms & entailments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e0b6bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marcu\\anaconda3\\envs\\nlp\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import json\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21c16048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load LDA model\n",
    "lda = gensim.models.ldamodel.LdaModel.load('../../data/topic-model/lda/exp4.model')\n",
    "\n",
    "# This creates and returns a dictionary with the topics (1-15) as the keys. The values will be the top N words of each topic.\n",
    "# Top N words = 30\n",
    "topic_dict = {'Topic ' + str((i+1)): [token for token, score in lda.show_topic(i, topn=30)] for i in range(0, lda.num_topics)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0cd7eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordnet(list):\n",
    "    '''\n",
    "    This function takes in a list of tokens and gets the synonyms, hyponyms, hypernyms, meronyms, holonyms & entailments for each token.\n",
    "    Duplicates are avoided by using set().\n",
    "    Returns them as a set.\n",
    "    '''\n",
    "    wordnet = set()\n",
    "    for token in list:\n",
    "        for synset in wn.synsets(token):\n",
    "            for lemma in synset.lemmas():\n",
    "                wordnet.add(lemma.name())\n",
    "            for hypernym in synset.hypernyms():\n",
    "                for lemma in hypernym.lemma_names():\n",
    "                    wordnet.add(lemma)\n",
    "            for hyponym in synset.hyponyms():\n",
    "                for lemma in hyponym.lemma_names():\n",
    "                    wordnet.add(lemma)\n",
    "            for meronym in synset.part_meronyms():\n",
    "                for lemma in meronym.lemma_names():\n",
    "                    wordnet.add(lemma)\n",
    "            for holonym in synset.part_holonyms():\n",
    "                for lemma in holonym.lemma_names():\n",
    "                    wordnet.add(lemma)\n",
    "            for entailment in synset.entailments():\n",
    "                for lemma in entailment.lemma_names():\n",
    "                    wordnet.add(lemma)\n",
    "\n",
    "    return wordnet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2853e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand the Top N words\n",
    "expanded_topic_dict = {}\n",
    "for key,value in topic_dict.items():\n",
    "    expanded_topic_dict[key] = list(wordnet(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4aa3618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the expanded topic dictionary in JSON format\n",
    "# Serialize data into file:\n",
    "json.dump(expanded_topic_dict, open(\"../../data/topic-model/topN/exp4.json\", 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f91c1d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
